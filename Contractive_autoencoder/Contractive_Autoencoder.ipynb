{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Contractive Autoencoder_.ipynb",
      "version": "0.3.2",
      "provenance": []
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.1"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FX5lwi_YZUNd",
        "colab_type": "text"
      },
      "source": [
        "# Shubham Sharma\n",
        "## IIT BOMBAY\n",
        "\n",
        "\n",
        "This is a basic code for contractive autoencoder."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iBLFHytwJ7iV",
        "colab_type": "code",
        "outputId": "7920ec22-df05-44d1-818c-00c15ac25064",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 445
        }
      },
      "source": [
        "from __future__ import division, print_function, absolute_import\n",
        "\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Import MNIST data\n",
        "from tensorflow.examples.tutorials.mnist import input_data\n",
        "mnist = input_data.read_data_sets(\"/tmp/data/\", one_hot=True)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING: Logging before flag parsing goes to stderr.\n",
            "W0703 10:12:23.802644 140384207398784 deprecation.py:323] From <ipython-input-1-af7bdde62763>:8: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
            "W0703 10:12:23.807456 140384207398784 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please write your own downloading logic.\n",
            "W0703 10:12:23.810437 140384207398784 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use tf.data to implement this functionality.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Extracting /tmp/data/train-images-idx3-ubyte.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "W0703 10:12:24.097955 140384207398784 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use tf.data to implement this functionality.\n",
            "W0703 10:12:24.101504 140384207398784 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:110: dense_to_one_hot (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use tf.one_hot on tensors.\n",
            "W0703 10:12:24.160852 140384207398784 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Extracting /tmp/data/train-labels-idx1-ubyte.gz\n",
            "Extracting /tmp/data/t10k-images-idx3-ubyte.gz\n",
            "Extracting /tmp/data/t10k-labels-idx1-ubyte.gz\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MXp-udv1J7id",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Training Parameters\n",
        "learning_rate = 0.001\n",
        "num_steps = 10000\n",
        "#num_steps=50000\n",
        "batch_size = 200\n",
        "\n",
        "display_step = 500\n",
        "examples_to_show = 10\n",
        "\n",
        "# Network Parameters\n",
        "num_hidden_1 = 20 #200 # 1st layer num features\n",
        "num_hidden_2 = 20 #90 # 2nd layer num features (the latent dim)\n",
        "num_input = 784 # MNIST data input (img shape: 28*28)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-mMwj1W2J7ii",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# tf Graph input (only pictures)\n",
        "X = tf.placeholder(\"float\", [None, num_input])\n",
        "\n",
        "weights = {\n",
        "    'encoder_h1': tf.Variable(tf.random_normal([num_input, num_hidden_1])),\n",
        "    'encoder_h2': tf.Variable(tf.random_normal([num_hidden_1, num_hidden_2])),\n",
        "    'decoder_h1': tf.Variable(tf.random_normal([num_hidden_2, num_hidden_1])),\n",
        "    'decoder_h2': tf.Variable(tf.random_normal([num_hidden_1, num_input])),\n",
        "}\n",
        "biases = {\n",
        "    'encoder_b1': tf.Variable(tf.random_normal([num_hidden_1])),\n",
        "    'encoder_b2': tf.Variable(tf.random_normal([num_hidden_2])),\n",
        "    'decoder_b1': tf.Variable(tf.random_normal([num_hidden_1])),\n",
        "    'decoder_b2': tf.Variable(tf.random_normal([num_input])),\n",
        "}\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nhq_m2zbJ7io",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Building the encoder\n",
        "def encoder(x):\n",
        "    # Encoder Hidden layer with sigmoid activation #1\n",
        "    layer_1 = (tf.add(tf.matmul(x, weights['encoder_h1']),\n",
        "                                   biases['encoder_b1']))\n",
        "    # Encoder Hidden layer with sigmoid activation #2\n",
        "    layer_2 = (tf.add(tf.matmul(layer_1, weights['encoder_h2']),\n",
        "                                   biases['encoder_b2']))\n",
        "    return layer_2\n",
        "\n",
        "\n",
        "# Building the decoder\n",
        "def decoder(x):\n",
        "    # Decoder Hidden layer with sigmoid activation #1\n",
        "    layer_1 = (tf.add(tf.matmul(x, weights['decoder_h1']),\n",
        "                                   biases['decoder_b1']))\n",
        "    # Decoder Hidden layer with sigmoid activation #2\n",
        "    layer_2 = (tf.add(tf.matmul(layer_1, weights['decoder_h2']),\n",
        "                                   biases['decoder_b2']))\n",
        "    return layer_2\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2MfIL2VpJ7is",
        "colab_type": "code",
        "outputId": "e2eb9b1c-f99d-4fed-f53b-57181a71a96a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        }
      },
      "source": [
        "# Construct model\n",
        "encoder_op = encoder(X)\n",
        "decoder_op = decoder(encoder_op)\n",
        "\n",
        "# Prediction\n",
        "y_pred = decoder_op\n",
        "# Targets (Labels) are the input data.\n",
        "y_true = X\n",
        "\n",
        "from tensorflow.python.ops.parallel_for.gradients import jacobian\n",
        "J=jacobian(encoder_op,X)\n",
        "\n",
        "# Define loss and optimizer, minimize the squared error\n",
        "loss = tf.reduce_mean(tf.pow(y_true - y_pred, 2))\n",
        "regularized_term = tf.norm(J)\n",
        "#regularized_term = 0\n",
        "\n",
        "\n",
        "contractive_loss = regularized_term + loss\n",
        "optimizer = tf.train.RMSPropOptimizer(learning_rate).minimize(contractive_loss)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "W0703 10:12:24.694988 140384207398784 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_grad.py:1205: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "W0703 10:12:24.817616 140384207398784 deprecation.py:506] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/rmsprop.py:119: calling Ones.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SLnmQSP8J7iv",
        "colab_type": "code",
        "outputId": "22283666-b33c-42e0-9c85-22dfc87c90fd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 390
        }
      },
      "source": [
        "# Initialize the variables (i.e. assign their default value)\n",
        "init = tf.global_variables_initializer()\n",
        "loss_list=[]\n",
        "# Start Training\n",
        "# Start a new TF session\n",
        "with tf.Session() as sess:\n",
        "\n",
        "    # Run the initializer\n",
        "    sess.run(init)\n",
        "\n",
        "    # Training\n",
        "    for i in range(1, num_steps+1):\n",
        "        # Prepare Data\n",
        "        # Get the next batch of MNIST data (only images are needed, not labels)\n",
        "        batch_x, _ = mnist.train.next_batch(batch_size)\n",
        "\n",
        "        # Run optimization op (backprop) and cost op (to get loss value)\n",
        "        _, l = sess.run([optimizer, contractive_loss], feed_dict={X: batch_x})\n",
        "        # Display logs per step\n",
        "        if i % display_step == 0 or i == 1:\n",
        "          print('Step %i: Minibatch Loss: %f' % (i, l))\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Step 1: Minibatch Loss: 574909.750000\n",
            "Step 500: Minibatch Loss: 6500.844727\n",
            "Step 1000: Minibatch Loss: 1466.479492\n",
            "Step 1500: Minibatch Loss: 54.894550\n",
            "Step 2000: Minibatch Loss: 8.872515\n",
            "Step 2500: Minibatch Loss: 13.720474\n",
            "Step 3000: Minibatch Loss: 13.482314\n",
            "Step 3500: Minibatch Loss: 14.039104\n",
            "Step 4000: Minibatch Loss: 13.863711\n",
            "Step 4500: Minibatch Loss: 13.860048\n",
            "Step 5000: Minibatch Loss: 13.632374\n",
            "Step 5500: Minibatch Loss: 13.401568\n",
            "Step 6000: Minibatch Loss: 13.897683\n",
            "Step 6500: Minibatch Loss: 13.669905\n",
            "Step 7000: Minibatch Loss: 13.721952\n",
            "Step 7500: Minibatch Loss: 13.787473\n",
            "Step 8000: Minibatch Loss: 13.431569\n",
            "Step 8500: Minibatch Loss: 13.598118\n",
            "Step 9000: Minibatch Loss: 13.980861\n",
            "Step 9500: Minibatch Loss: 13.733674\n",
            "Step 10000: Minibatch Loss: 13.585894\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JZ8ZQqJyJ7ix",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}